# ğŸ§  AI-Driven SQL Generation from Natural Language

> An LLM-centric project that automatically derives SQL queries from natural language database questions and executes them efficiently using DuckDB.

---

## ğŸš€ Project Summary

This repository demonstrates how **Large Language Models (LLMs)** and programmatic SQL tooling can be combined to:

âœ¨ Translate or interpret **natural language database questions**
âœ” Generate **production-ready SQL queries**
ğŸ“Š Execute those queries using **DuckDB**
ğŸ“ Operate on real CSV datasets representing relational structures

It showcases **practical Text-to-SQL capabilities** applicable to data analytics, BI tools, intelligent query systems, and AI-augmented database tooling â€” a skillset highly relevant for AI/ML and LLM engineering roles. ([GitHub][1])

---

## ğŸ“‚ Repository Contents

```
Database-SQL-generation-via-LLM/
â”‚
â”œâ”€â”€ Q1.py
â”œâ”€â”€ Q2.py
â”œâ”€â”€ Q3.py
â”œâ”€â”€ Q4.py
â”œâ”€â”€ Q5.py
â”œâ”€â”€ README.pdf
â”œâ”€â”€ *.csv (10 relational CSV tables)
â””â”€â”€ .DS_Store
```

**Key components explained:**

| Component         | Purpose                                                      |               |
| ----------------- | ------------------------------------------------------------ | ------------- |
| `Q1.py` â€“ `Q5.py` | Python scripts that run SQL queries using DuckDB on CSV data |               |
| `.csv` files      | Tables representing a classroom / research data model        |               |
| `README.pdf`      | Original project documentation and screenshots               |               |
| `.DS_Store`       | System metadata (can be removed)                             | ([GitHub][1]) |

---

## ğŸ§© Project Workflow

1. **Dataset Representation**

   * Each `.csv` is a table such as `course`, `instructor`, `team`, `rating`, etc.
   * Together they model a database similar to a university or project ecosystem. ([GitHub][1])

2. **SQL Execution with DuckDB**

   * DuckDB is used to execute SQL directly on CSV files â€” enabling fast prototyping without setting up a DB engine.
   * Example:

     ````python
     import duckdb
     result = duckdb.sql("SELECT â€¦ FROM 'table.csv' â€¦")
     result.show()
     ``` :contentReference[oaicite:3]{index=3}

     ````

3. **Scripted Queries**
   Each Python file answers a natural language question by:

   * Generating SQL (manually or via a prompt pipeline)
   * Running it on CSV data
   * Printing formatted results

---

## ğŸ“Š Query Descriptions

Hereâ€™s what each script computes:

| Script    | Question Being Answered                                                  |
| --------- | ------------------------------------------------------------------------ |
| **Q1.py** | Which course has the most students?                                      |
| **Q2.py** | Which instructor teaches the most students?                              |
| **Q3.py** | Which instructor has the highest average rating?                         |
| **Q4.py** | List all classes with their enrollment counts, sorted by popularity      |
| **Q5.py** | Compute the total pay for a specific instructor (teaching + supervision) |

Each script is structured to:
âœ” Load datasets
âœ” Execute SQL with DuckDB
âœ” Print results clearly using `result.show()` ([GitHub][2])

---

## ğŸ“Œ Example Output

A typical script prints results like:

```
============================================================
Q1: Course with Most Number of Students
============================================================
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ course_name â”‚ students  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Data Sci 101â”‚ 124       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

This replicates real data analytics workflow patterns.

---

## ğŸ§  Skills & Techniques Demonstrated

This project highlights the following:

âœ” **Text-to-SQL reasoning pipelines**
âœ” **Structured SQL generation logic**
âœ” **Programmatic data processing using DuckDB**
âœ” **Handling relational data via CSV in Python**
âœ” **Evaluation of generated queries against real data**

These are directly applicable to:

* **AI/ML Engineering**
* **LLM System Design**
* **Data Engineering**
* **Business Intelligence tooling**
* **Data Analytics Automation**

---

## ğŸ“ˆ Why This Project Is Valuable for Recruiters

This project showcases practical real-world AI and database skills:

* You can **bridge natural language understanding with structured database logic**
* You demonstrate knowledge of **DuckDB as an analytics engine**
* You show how to **operationalize machine-generated SQL queries**
* You illustrate ability to **work with real datasets without heavy DB setup**
* The project can be extended into **AI-augmented database applications**

---

## ğŸ“¦ Next Steps / Extensions

Here are ways to evolve the project in a portfolio:

ğŸ”¹ Add a **prompt-based LLM interface** that takes text â†’ generates SQL
ğŸ”¹ Integrate a **web/UI layer** (e.g., Streamlit) for interactively querying
ğŸ”¹ Build a **benchmark evaluation suite** for comparing SQL generation models
ğŸ”¹ Expand to **multi-schema databases** and optimize SQL logic

---

## ğŸ›  How to Run Locally

1. Clone the repository:

   ```bash
   git clone https://github.com/AtharvaThorat/Database-SQL-generation-via-LLM
   ```
2. Install dependencies:

   ```bash
   pip install duckdb
   ```
3. Run any query script:

   ```bash
   python Q1.py
   ```

   Results will print in the terminal.

---

## ğŸ“£ Final Notes

This project is a strong demonstration of how AI (particularly LLMs) can be integrated with traditional database technologies to make data querying more intuitive and efficient â€” a highly desirable ability in modern tech roles focused on **AI-augmented tooling** and **data workflows**. ([arXiv][3])

